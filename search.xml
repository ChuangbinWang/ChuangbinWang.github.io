<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[ssl证书理解]]></title>
    <url>%2F2019%2F11%2F08%2Fssl%E8%AF%81%E4%B9%A6%E7%90%86%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[昨天在配置公司服务器的ssl证书的时候发现了一个问题。起因大概是公司申请的域名里面只有一个是有chain文件的，而其他的域名是没有chain文件，（具体原因应该是申请这些文件很麻烦吧。听老板说的）所以在进行亚马逊智能家居测试的时候就遇到，能访问到我们的https的网站，且显示是安全的，但是亚马逊调用我们的接口获取OAuth2.0的token时，我们这边一直接收不到https请求。通过排查得知，调用方在调用请求之前，会去通过他们系统内部的根证书和从访问的域名出获取chain文件进行验证数字签名的合法性。如果校验不通过或者缺乏chain文件，在进行请求的时候会报unable to verify the first certificate这个错误。借此机会，我去学习了ssl证书的基本知识，并总结了一点结构图，仅供参考。https://mubu.com/doc/708-IhZOg0]]></content>
  </entry>
  <entry>
    <title><![CDATA[阅读白帽子讲web安全读书笔记]]></title>
    <url>%2F2019%2F11%2F03%2F%E9%98%85%E8%AF%BB%E7%99%BD%E5%B8%BD%E5%AD%90%E8%AE%B2web%E5%AE%89%E5%85%A8%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[这周末去了腾讯滨海大厦，确实很高大上。但是由于朋友提供的访客码出了问题联不上wifi,所以只抽出了点时间读了一下白帽子讲web安全这本书，并进行了整理了一些学习到的内容，做成了体系图。只有第一，二章。https://mubu.com/doc/tRqvksQvP0]]></content>
  </entry>
  <entry>
    <title><![CDATA[腾讯面试]]></title>
    <url>%2F2019%2F10%2F28%2F%E8%85%BE%E8%AE%AF%E9%9D%A2%E8%AF%95%2F</url>
    <content type="text"><![CDATA[前几天去腾讯面试了，二面直接问一些设计的问题。我很头疼。。。https://mubu.com/doc/AhUpMNP8-0]]></content>
  </entry>
  <entry>
    <title><![CDATA[数据结构与算法体系图]]></title>
    <url>%2F2019%2F10%2F20%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E4%BD%93%E7%B3%BB%E5%9B%BE%2F</url>
    <content type="text"><![CDATA[今天周末，最近也感觉在这种画逻辑图的方法很不错，对于加强知识的记忆，对自己的知识也有了体系，下一次复习的时候也可以通过知识点复习。现在想想校招那种随便看看确实还是太嫩了，有了拓扑结构图，对整个计算机也有了更全面的认识。特此贴出：https://mubu.com/doc/BYQlfRlIQ0]]></content>
  </entry>
  <entry>
    <title><![CDATA[数据结构与算法体系图]]></title>
    <url>%2F2019%2F10%2F20%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E4%BD%93%E7%B3%BB%E5%9B%BE-1%2F</url>
    <content type="text"><![CDATA[今天周末，最近也感觉在这种画逻辑图的方法很不错，对于加强知识的记忆，对自己的知识也有了体系，下一次复习的时候也可以通过知识点复习。现在想想校招那种随便看看确实还是太嫩了，有了拓扑结构图，对整个计算机也有了更全面的认识。特此贴出：https://mubu.com/doc/BYQlfRlIQ0]]></content>
  </entry>
  <entry>
    <title><![CDATA[进程线程知识体系]]></title>
    <url>%2F2019%2F10%2F17%2F%E8%BF%9B%E7%A8%8B%E7%BA%BF%E7%A8%8B%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%2F</url>
    <content type="text"><![CDATA[由于多线程，多进程编程也是c++开发工程师必备的技能。最近在复习期间也做了相应整理。https://mubu.com/doc/tg53hT94H0]]></content>
  </entry>
  <entry>
    <title><![CDATA[linux命令行集]]></title>
    <url>%2F2019%2F10%2F13%2Flinux%E5%91%BD%E4%BB%A4%E8%A1%8C%E9%9B%86%2F</url>
    <content type="text"><![CDATA[同样也考察了我shell语句，特别是对awk, sed, grep, find之间的配合使用，好像大部分考察你对shell的熟练程度也都是通过这几个文本处理指令。借此机会我也进行了复习。https://mubu.com/doc/paDuvIX4t0]]></content>
  </entry>
  <entry>
    <title><![CDATA[MySql指令集]]></title>
    <url>%2F2019%2F10%2F13%2FMySql%E6%8C%87%E4%BB%A4%E9%9B%86%2F</url>
    <content type="text"><![CDATA[这几天找工作，确实挺难的，难在我的方向上面，自己本身是学嵌入式开发的，后来由于一些特殊情况转到现在这家公司，主要写的是业务后台，但是公司框架老旧，使用的还是c语言，且也不用些流行的工具。所以这次找工作吃了大亏，用c语言写后台开发的公司太少了，要也是一些资历老一点的，专注写底层的。这一次有面试也是投了很久的简历了。这次问的问题主要还是MySql。由于本来自己很少用，基本就是傻眼，这次专门总结一下，画了个关系图。https://mubu.com/doc/iMhBL2wzH0]]></content>
  </entry>
  <entry>
    <title><![CDATA[TFS大文件系统-Hash引擎]]></title>
    <url>%2F2019%2F10%2F08%2FTFS%E5%A4%A7%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F-Hash%E5%BC%95%E6%93%8E%2F</url>
    <content type="text"><![CDATA[本文章是通过阅读淘宝的大文件系统的hash引擎源码而进行的一些总结。主要是关于传统文件系统的特点，传统文件系统面临的问题，淘宝大文件系统的结构。http://note.youdao.com/noteshare?id=327adfe8ca42e044ee61fa6ec15b8041]]></content>
  </entry>
  <entry>
    <title><![CDATA[Redis源码阅读-字符串命令]]></title>
    <url>%2F2019%2F10%2F08%2FRedis%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB-%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[同样的，通过阅读https://blog.csdn.net/men_wen/article/details/70325566 源码。得到以下流程总结。https://mubu.com/doc/9666FOvx_0]]></content>
  </entry>
  <entry>
    <title><![CDATA[Redis源码阅读-对象系统]]></title>
    <url>%2F2019%2F10%2F08%2FRedis%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB-%E5%AF%B9%E8%B1%A1%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[通过阅读https://blog.csdn.net/men_wen/article/details/70257207 得出来的一些总结。由于有比较好的思维导图工具-幕布，我就将主要的结构体贴出来。https://mubu.com/doc/u5GWOhyKr0由于思维导图导出要会员。。先将就的放出来。]]></content>
      <categories>
        <category>源码阅读</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hash函数-有点东西的]]></title>
    <url>%2F2019%2F09%2F29%2Fhash-%E6%9C%89%E7%82%B9%E4%B8%9C%E8%A5%BF%E7%9A%84%2F</url>
    <content type="text"><![CDATA[在阅读redis源码的时候，发现hash实现的方法有很多，当时又在想为什么要那么多的hash算法，原来只是知道这个东西是一种散列方法，将一些特定的文件或者字符串转换为固定长度的字符串，这样就可以通过识别这些类型文件或字符的hash值来识别文件，有点类似指纹的作用。到这里又想到，公司让我最近做的一个项目就是做一个OAuth2.0的鉴权模块，其主要作用就是根据客户账户密码生成一个token，然后通过这个token来标识用户。后来想想这个token应该得有这些特点：简单和均匀。简单指散列函数的计算简单快速；均匀指对于关键字集合中的任一关键字，散列函数能以等概率将其映射到表空间的任何一个位置上。也就是说，散列函数能将子集k随机均匀地分布在表的地址集{0，1，…，m-1}上，以使冲突最小化。有必要再次提醒大家的是，hash函数的选择必须慎重，如果不幸所有的元素之间都产生了冲突，那么hash表将退化为链表，其性能会大打折扣，时间复杂度迅速降为O(n)，绝对不要存在任何侥幸心理，因为那是相当危险的。历史上就出现过利用Linux内核hash函数的漏洞，成功构造出大量使hash表发生碰撞的元素，导致系统被DoS，所以目前内核的大部分hash函数都有一个随机数作为参数进行掺杂，以使其最后的值不能或者是不易被预测。这又对 hash函数提出了第二点安全方面的要求：hash函数最好是单向的，并且要用随机数进行掺杂。提到单向，你也许会想到单向散列函数md4和md5，很不幸地告诉你，他们是不适合的，因为hash函数需要有相当好的性能。常用散列函数：（1）直接定址法比如在一个0～100岁的年龄统计表，我们就可以把年龄大小作为地址。但是这种情况，如果数据源大，冲突概率高。（2）除留余数法f( key ) = key mod p ( p ≤ m )选择取模的数应该选离长度值最近的最大质数（3 blizzard网上流传最具传奇色彩的莫过于暴雪公司的魔兽文件打包管理器里的hashTable的实现了；在冲突方面的处理方面，采用线性探索后再散列。在添加和查找过程中进行了三次哈希，第一个哈希值用来查找，后两个哈希值用来校验，这样可以大大减少冲突的几率。MPQs使用一个存放文件名的哈希表来跟踪文件内部，但是表的格式与通常方法有点不同，首先不像通常的做法使用哈希值作为偏移量，存储实际的文件名。MPQs 根本不存储文件名，而是使用了三个不同的哈希值：一个用做哈希表偏移量，两个用作核对。这两个核对的哈希值用于替代文件名。当然从理论上说存在两个不同的文件名得到相同的三个哈希值，但是这种情况发送的几率是：1:18889465931478580854784,这应该足够安全了。(4)times33哈希算法http://www.nowamagic.net/academy/detail/3008095 对于它的介绍在此链接。某人试着测试1到256之间的每个数字，他会发现，没有哪一个数字的表现是特别突出的。其中的128个奇数(1除外)的表现都差不多，都能够达到一个能接受的哈希分布，平均分布率大概是86%。数字33以及其他一些同样好的数字比如 17,31,63,127和129对于其他剩下的数字，在面对大量的哈希运算时，仍然有一个大大的优势，就是这些数字能够将乘法用位运算配合加减法来替换，这样的运算速度会提高。这是redis内的times33的计算方法：12345678910/* 这里提供了一种比较简单的哈希算法 */unsigned int dictGenCaseHashFunction(const unsigned char *buf, int len) { //以djb hash为基础，俗称“times33”就是不断的乘33 //几乎所有的流行的hash map都采用了DJB hash function unsigned int hash = (unsigned int)dict_hash_function_seed; while (len--) hash = (hash * 33) + (tolower(*buf++)); //本来是用位移的方法，但是生成静态文件的时候就出错 return hash;}而33 的2进制就是100001,比如abc经过times33得到的结果就是100001 + ‘a’, 100001 + ‘b’,100001 + ‘c’两种hash函数的对比和评价nowamagic.net/academy/detail/3008097一般的hash表，在找到hash bucket之后，就逐个的直接比较element；而blizzard的这个hash表，则是用“额外的两个hash值的比较”来代替element的直接比较。孰优孰劣要看具体的应用环境。（5）开放定址法所谓的开放定址法就是一旦发生了冲突，就去寻找下一个空的散列地址，只要散列表足够大，空的散列地址总能找到，并将记录存入。或者 当冲突发生时，使用某种探测技术在散列表中形成一个探测序列。沿此序列逐个单元地查找，直到找到给定的关键字，或者碰到一个开放的地址（即该地址单元为空）为止（若要插入，在探查到开放的地址，则可将待插入的新结点存人该地址单元）。查找时探测到开放的地址则表明表中无待查的关键字，即查找失败。这个称为线性探索其中这种解决冲突的方式还有二次探测法 fi(key) = (f(key)+di) MOD m (di = 12, -12, 22, -22,……)随机探测法 对于位移量 di 采用随机函数计算得到，我们称之为随机探测法。链地址法 即通过链表来连接hash（key）冲突的节点。由于冲突的存在，所以对hash桶的个数的设计也非常的需要技巧;在linux内核中，hash函数hash_long（计算hash桶的个数），用了golden ratio来计算。因为桶(bits)的数量需要由hash函数和对冲突的期望来决定，那么在实际项目中，我们对于计算hash桶个数这样的hash函数，应该怎么确定桶的数量呢？一般情况下都是自己根据数据特性来考虑使用的 hash 算法，不是千篇一律咬死一个不放。比如存放 IP 地址的 hash table，用一个 65536 的桶就很好，把 IP 的后 16bit 作为 key。这种方法绝对比 hash_long、jhash 等函数的碰撞率低。其实就是这个界和性能的折中。我可以取我问题空间的最大值。这样肯定能保证键值分散。但是这样会浪费很多空间。然而取得太小，又影响查找效率。感觉还是要在试验中进行测试。而且个人觉得，hash比其他搜索的数据结构灵活的地方就是它的可定制性。可以根据具体情况调整，以达到最优的效果。通常在进行评判hash函数的时候，还是主要看冲突情况，和计算性能。其中通过是使用大量数据进行hash分布，然后统计冲突个数，占总数的比率。]]></content>
  </entry>
  <entry>
    <title><![CDATA[服务器端与客户端app建立长连接]]></title>
    <url>%2F2019%2F09%2F28%2F%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%AB%AF%E4%B8%8E%E5%AE%A2%E6%88%B7%E7%AB%AFapp%E5%BB%BA%E7%AB%8B%E9%95%BF%E8%BF%9E%E6%8E%A5%2F</url>
    <content type="text"><![CDATA[服务器端与客户端app建立长连接常用的方法有：1.一种是定时去server查询数据，通常是使用HTTP协议来访问web服务器，称Polling（轮询）；2.还有一种是移动端和服务器建立长连接，使用XMPP长连接，称Push（推送）。对比：从耗费的电量、流量和数据延迟性各方面来说，Push有明显的优势。但是使用Push的缺点是：对于客户端：实现和维护相对成本高，在移动无线网络下维护长连接，相对有一些技术上的开发难度。对于服务器：如何实现多核并发，cpu作业调度，数量庞大的长连接并发维护等技术，仍存在开发难点。移动无线网络的特点：因为 IP v4 的 IP 量有限，运营商分配给手机终端的 IP 是运营商内网的 IP，手机要连接 Internet，就需要通过运营商的网关做一个网络地址转换（Network Address Translation，NAT）。简单的说运营商的网关需要维护一个外网 IP、端口到内网 IP、端口的对应关系，以确保内网的手机可以跟 Internet 的服务器通讯，GGSN（Gateway GPRS Support Node 网关GPRS支持结点）模块就实现了NAT功能。因为大部分移动无线网络运营商都是为了减少网关的NAT映射表的负荷，所以如果发现链路中有一段时间没有数据通讯时，会删除其对应表，造成链路中断。既然我们知道我们移动端要和Internet进行通信，必须通过运营商的网关，所以，为了不让NAT映射表失效，我们需要定时向Internet发送数据，为了不让NAT映射表失效，所以只需发送长度为0的数据即可。介绍完特点后，分析服务器端的压力所在：假设一台服务器维护10万个长连接，当有1000万用户量时，需要有多达100台的服务器来维护这些用户的长连接，这里还不算用于做备份的服务器，这将会是一个巨大的成本问题。那就需要我们尽可能提高单台服务器接入用户的量，也就是业界已经讨论很久了的 C10K 问题。C2000K针对这个问题，他们专门成立了一个项目，命名为C2000K，顾名思义，他们的目标是单机维持200万个长连接。最终他们采用了多消息循环、异步非阻塞的模型]]></content>
  </entry>
  <entry>
    <title><![CDATA[NAT穿墙需要注意的地方]]></title>
    <url>%2F2019%2F09%2F28%2FNAT%E4%BC%A0%E5%A2%99%E9%9C%80%E8%A6%81%E6%B3%A8%E6%84%8F%E7%9A%84%E5%9C%B0%E6%96%B9%2F</url>
    <content type="text"><![CDATA[简单说下TCP穿透原理吧,分四种情况：1.建立TCP等待连接方和请求TCP连接方在同一个子网，或者是外网（不用穿透）2.建立TCP等待连接方在外网，请求TCP连接方在内网（请求方会先发请求信息，同时为建立方打洞）3.建立TCP等待连接方在内网，请求TCP连接方在外网（需要第三方服务器，原理同上面的UDP穿透一样）4.建立TCP等待连接方，请求TCP连接方分别在不同的子网（需要第三方服务器，原理同上面的UDP穿透一样）**不足：存在多个NAT的嵌套NAPT IP地址端口号转换没有考虑进去路由器中的session的生命周期的不确定（有时候是几分钟，有时候几个小时不定），所以需要定期地进行穿透等。***]]></content>
  </entry>
  <entry>
    <title><![CDATA[简单说明]]></title>
    <url>%2F2019%2F09%2F24%2F%E7%AE%80%E5%8D%95%E8%AF%B4%E6%98%8E%2F</url>
    <content type="text"><![CDATA[由于本人看好像有个博客还是挺好看的，而且自己的笔记是放在有道云的，且也很少整理，在加上，最近在找工作，复习的时候也是总结的过程。所以开这个博客用于将自己的笔记整理出来，一方面是复习复习原来的学习的知识，二是弄一个博客，以后需要找工作的时候，也有点东西可以展示个其他的人。 近期也会抽出时间来将有道云上的东西迁移上来。如果大家发现有什么内容有兴趣或者是错误，欢迎在下面留言区提出。谢谢！！]]></content>
  </entry>
  <entry>
    <title><![CDATA[Redis源码阅读-RIO]]></title>
    <url>%2F2019%2F09%2F24%2FRedis%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB-RIO%2F</url>
    <content type="text"><![CDATA[通过阅读Redis源码和参考他人的讲解后，对Redis的RIO模型进行些许总结。本篇文章参考自：https://blog.csdn.net/men_wen/article/details/71131550首先阅读一下核心结构体：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849struct _rio { // 读，写，读写偏移量、冲洗操作的函数指针，非0表示成功 size_t (*read)(struct _rio *, void *buf, size_t len); size_t (*write)(struct _rio *, const void *buf, size_t len); off_t (*tell)(struct _rio *); int (*flush)(struct _rio *); // 计算和校验函数 void (*update_cksum)(struct _rio *, const void *buf, size_t len); /* The current checksum */ // 当前校验和 uint64_t cksum; /* number of bytes read or written */ // 读或写的字节数 size_t processed_bytes; // 每次读或写的最大字节数 size_t max_processing_chunk; /* Backend-specific vars. */ // 读写的各种对象 union { /*内存缓冲区 In-memory buffer target. */ struct { sds ptr; //缓冲区的指针，本质是char * off_t pos; //缓冲区的偏移量 } buffer; /*标准文件IO Stdio file pointer target. */ struct { FILE *fp; // 文件指针，指向被打开的文件 off_t buffered; /* 最近一次同步之后所写的字节数 Bytes written since last fsync. */ off_t autosync; /* 写入设置的autosync字节后，会执行fsync()同步 fsync after 'autosync' bytes written. */ } file; /*文件描述符 */ struct { int *fds; /*文件描述符数组 File descriptors. */ int *state; /*每一个fd所对应的errno Error state of each fd. 0 (if ok) or errno. */ int numfds; // 数组长度，文件描述符个数 off_t pos; // 偏移量 sds buf; // 缓冲区 } fdset; } io;};typedef struct _rio rio;巧妙的地方是，rio结构体运用封装的方法，定义了几个通用函数，对于使用I/O缓冲区或是文件描述符缓冲区或是标准输入输出I/O的变量只需将对应的函数赋值到rio定义的方法中，以便于统一由rio提供。使用union结构体封装不同的I/O操作对象。需要注意的是对文件描述符进行同步磁盘的过程，是一段段同步的，最大为1024字节rio还提供了校验和计算的函数，设置自动同步字节限制函数（针对文件描述符），rio还基于AOF协议封装了AOF协议，以便于进行AOF持久化的时候进行格式整理。具体函数的原理可以通过阅读AOF协议。同样，贴出源码注释：rio.c源码阅读rio.h源码阅读]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis源码阅读-字典]]></title>
    <url>%2F2019%2F09%2F24%2FRedis%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB-%E5%AD%97%E5%85%B8%2F</url>
    <content type="text"><![CDATA[这一篇文章就不像前两篇那么大费篇幅了。主要介绍一下其中重要的结构体关系，和一些灵活巧妙的地方。然后还放字典相关文件，内部提供了相关的注释。本文参考链接https://blog.csdn.net/men_wen/article/details/69787532字典又称为符号表（symbol table）、关联数组（associative array）或映射（map），是一种用于保存键值对（key-value pair）的抽象数据结构。例如：redis中的所有key到value的映射，就是通过字典结构维护，还有hash类型的键值。123456789101112131415161718192021222324252627282930313233343536373839typedef struct dictht { //字典实体 dictEntry **table; //哈希表table的大小，初始化大小为4 unsigned long size; unsigned long sizemask;//用于将哈希值映射到table的位置索引。它的值总是等于(size-1)。 //正在被使用的数量 unsigned long used;} dictht;/* 字典主操作类 */typedef struct dict { //字典类型 dictType *type; //私有数据指针 void *privdata; //字典哈希表，共2张，一张旧的，一张新的 dictht ht[2]; //重定位哈希时的下标 long rehashidx; /* rehashing not in progress if rehashidx == -1 */ //当前迭代器数量 int iterators;} dict;/* 字典结构体，保存K-V值的结构体 */typedef struct dictEntry { //字典key函数指针 void *key; union { void *val; //无符号整型值 uint64_t u64; //有符号整型值 int64_t s64; double d; } v; //下一字典结点 struct dictEntry *next;} dictEntry;其中巧妙的地方在使用hash表记录字典数据，一个hash表对应组数据节点，每个节点由一个键值对组成。使用两个hash表和rehashidx标志位，当需要进行rehash的时候，可以设置rehashidx的标志位为已经rehash的节点个数。这样的做法的好处在于，当服务繁忙的时候，可以将rehash的过程暂停，且保证数据仍然保存在两个hash表中。sizemask的值问size-1，其突出的作用是正常的key进行hash后得到的hash值并不一定在小于size，然而hash表的大小只有size，那么其存放的位置只能通过 sizemask& hash(key) （取余操作）union的使用在rehash期间，每次对字典的添加、删除、查找、或更新操作时，都会判断是否正在进行rehash操作，如果是，则顺带进行单步rehash，并将rehashidx+1。dictEntry中的next指向的是hashkey冲突的下一个节点。Redis采用链式存储冲突key。特别要注意的地方在：判断是否需要扩容的时候，需要判断是否dict_can_resize标志位为0，或hash表的使用率大于安全值。默认安全值是hashtable.used/d->hashtable.size = 5，然后rehash后的hash表的大小，是不大于4的n次幂的大小。1234567891011static unsigned long _dictNextPower(unsigned long size){ unsigned long i = DICT_HT_INITIAL_SIZE; if (size >= LONG_MAX) return LONG_MAX; while(1) { if (i >= size) return i; i *= 2; }}hash表缩小的时候，如果小于阈值4，是不会再缩小的。在进行rehash的时候存在如下操作：其原始是在进行存入数据的时候有些桶为空，所以在计算rehashidx并非每次都比原来前进一个位置，而是有可能前进几个位置。1while(d->ht[0].table[d->rehashidx] == NULL) d->rehashidx++;源码阅读：dict.c源码阅读dict.h源码阅读]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis内存管理源码阅读记录]]></title>
    <url>%2F2019%2F09%2F23%2FRedis%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[Redis的zmalloc.c的主要功能包括有：统一函数名，记录堆空间申请大小，内存分配和释放，获取进程内存信息。本文参考链接https://cloud.tencent.com/developer/article/1383809统一函数名：Redis需要判断最终选择的内存管理库是否可以满足它的基础需求。比如Redis需要能够通过一个堆上分配的指针知晓其空间大小。但是并不是所有内存管理库的每个版本都有这个方法。于是对于不满足的就报错。比如libc的malloc方法在jemalloc中叫做je_malloc，而在tcmalloc中叫tc_malloc。这些基础方法并不多，它们分别是单片内存分配的malloc方法、多片内存分配calloc方法、内存重分配的realloc方法和内存释放函数free记录堆空间申请大小：Redis内存管理模块需要实时知道已经申请了多少空间，它通过一个全局变量保存：static size_t used_memory = 0;由于内存分配可能发生在各个线程中，所以对这个数据的管理要做到原子性。但是不同平台原子性操作的方法不同，有的甚至不支持原子操作，这个时候Redis就要统一它们的行为。一般来说，锁操作比原子操作慢。但是在不支持原子操作的系统上只能使用锁机制了。但是作为一个基础库，它不能仅仅考虑到多线程的问题。比如用户系统上不支持原子操作，而用户也不希望拥有多线程安全特性（可能它只有一个线程在运行），那么上述接口在计算时就必须使用锁机制，这样对于性能有苛刻要求的场景是不能接受的。于是Redis也有暴露了一个方法用于让用户指定是否需要启用线程安全特性。方法名：zmalloc_enable_thread_safeness相应的，线程安全的方法update_zmalloc_stat_add和update_zmalloc_stat_free需要被封装，以满足不同模式：内存分配和释放：一开始时，zmalloc直接分配了一个比申请空间大的空间，这就意味着无论是否支持获取申请空间大小的内存库，它都一视同仁了——实际申请比用户要求大一点。如果内存库支持，则通过zmalloc_size获取刚分配的空间大小，并累计到记录整个程序申请的堆空间大小上，然后返回申请了的地址。此时虽然用户申请的只是size的大小，但是实际给了size+PREFIX_SIZE的大小。如果内存库不支持，则在申请的内存前sizeof(size_t)大小的空间里保存用户需要申请的空间大小size。累计到记录整个程序申请堆空间大小上的也是实际申请的大小。最后返回的是偏移了头大小的内存地址。此时用户拿到的空间就是自己要求申请的空间大小。获取进程内存信息Redis不仅在代码层面要统计已申请的堆空间，还要通过其他方法获取本进程中一些内存信息。比如它要通过zmalloc_get_rss方法获取当前进程的实际使用物理内存。这个也要按系统支持来区分实现，比如支持/proc/%pid%/stat的使用.获取完物理内存数据后，可以通过和累计的分配内存大小相除，算出内存使用效率zmalloc_get_fragmentation_ratio除了上面这些方法，Redis还有获取已被修改的私有页面大小函数zmalloc_get_private_dirty以及获取物理内存（(RAM)）大小的zmalloc_get_memory_size方法。以下是我阅读源码文件后添加的注释。其中对一些细节进行了讲解，有兴趣的朋友可以下载阅读。zmalloc.c源码阅读zmalloc.h源码阅读]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis源码阅读记录]]></title>
    <url>%2F2019%2F09%2F23%2FRedis%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[此次源码地址是http://download.redis.io/releases/redis-3.2.8.tar.gz解压完之后，源码目录如图通过阅读文件名大概可以猜测他们的功能。Copying文件可以猜测出它是版本信息文件，我们可以不关心。Runtest、Runtest-cluster、Runtest-sentinel分别对应于“整体测试”、“分布式测试”和“主从切换测试”的脚本。Redis.conf和Seninel.conf分别对应于Redis的配置和主从配置。Deps应该它依赖的库，其目录如下一般来说，依赖库都是开源的第三方库。通过搜索得知Lua脚本引擎。Redis内嵌Lua脚本引擎，那么说明Redis需要Lua语言的解析能力。用户可以定制Lua脚本让Reids去执行，可以看出Redis开放了一个非常自由的接口供外部使用。Linenoise是一个命令行编辑库。这个是的Redis基础功能之一。它的相关资料可见https://github.com/antirez/linenoiseJemalloc是内存管理库。很多开源项目不使用glibc自带的ptmalloc，而是使用Jemalloc或者Tcmalloc这类更高效的内存管理库。Hiredis是Redis数据库的C接口。Geohash-int是一种地理编码算法。它将二维经纬度信息转换成Int型数据。在redis-3.2.8\tests目录下是测试相关的目录redis-3.2.8\utils目录结构：通过阅读主目录下的Makefile文件#Top level makefile, the real shit is at src/Makefiledefault: all.DEFAULT:cd src && $(MAKE) $@install:cd src && $(MAKE) $@.PHONY: install其代码主流程来自于src目录#Default allocatorifeq ($(uname_S),Linux)MALLOC=jemallocelseMALLOC=libcendif#Backwards compatibility for selecting an allocatorifeq ($(USE_TCMALLOC),yes)MALLOC=tcmallocendififeq ($(USE_TCMALLOC_MINIMAL),yes)MALLOC=tcmalloc_minimalendififeq ($(USE_JEMALLOC),yes)MALLOC=jemallocendififeq ($(USE_JEMALLOC),no)MALLOC=libcendiflinux系统上，Redis默认选择的内存管理库是jemalloc，其他系统则是选择libc的ptmalloc。当然还可以通过指定库来修改内存管理库。我们还可以选择tcmalloc或者tcmalloc_minimal。继续阅读MakeFile：#redis-server$(REDIS_SERVER_NAME): $(REDIS_SERVER_OBJ)$(REDIS_LD) -o $@ $^ ../deps/hiredis/libhiredis.a ../deps/lua/src/liblua.a $(REDIS_GEOHASH_OBJ) $(FINAL_LIBS)#redis-sentinel$(REDIS_SENTINEL_NAME): $(REDIS_SERVER_NAME)$(REDIS_INSTALL) $(REDIS_SERVER_NAME) $(REDIS_SENTINEL_NAME)#redis-check-rdb$(REDIS_CHECK_RDB_NAME): $(REDIS_SERVER_NAME)$(REDIS_INSTALL) $(REDIS_SERVER_NAME) $(REDIS_CHECK_RDB_NAME)#redis-cli$(REDIS_CLI_NAME): $(REDIS_CLI_OBJ)$(REDIS_LD) -o $@ $^ ../deps/hiredis/libhiredis.a ../deps/linenoise/linenoise.o $(FINAL_LIBS)#redis-benchmark$(REDIS_BENCHMARK_NAME): $(REDIS_BENCHMARK_OBJ)$(REDIS_LD) -o $@ $^ ../deps/hiredis/libhiredis.a $(FINAL_LIBS)#redis-check-aof$(REDIS_CHECK_AOF_NAME): $(REDIS_CHECK_AOF_OBJ)$(REDIS_LD) -o $@ $^ $(FINAL_LIBS)上面脚本可以见这个Makefile可以编译出6个不同的最终产物。其中最核心的应该是REDIS_SERVER_NAME对应的编译内容。我们从其需要链接的文件（REDIS_SERVER_OBJ中的内容）来看，程序的入口函数main应该位于server.o文件中。我们可以查看server.c文件学习。]]></content>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[elasticsearch底层存储原理]]></title>
    <url>%2F2019%2F09%2F23%2Felasticsearch%E5%BA%95%E5%B1%82%E5%AD%98%E5%82%A8%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[Elasticsearch 是一个建立在全文搜索引擎 Apache Lucene(TM) 基础上的搜索引擎，他能将每一个字段都编入索引，使其可以被搜索。本文的核心是探讨其作为搜索引擎的内部核心存储机制。本文总结自https://neway6655.github.io/elasticsearch/2015/09/11/elasticsearch-study-notes.htmlhttps://www.infoq.cn/article/database-timestamp-02/?utm_source=infoq&utm_medium=related_content_link&utm_campaign=relatedContent_articles_clkElasticsearch是面向文档型数据库，一条数据在这里就是一个文档，该文档属于一个User的类型，各种各样的类型会属于一个索引。其中用JSON作为文档序列化的格式，比如下面这条用户数据：{“name” : “John”,“sex” : “Male”,“age” : 25,“birthDate”: “1990/05/01”,“about” : “I love to go rock climbing”,“interests”: [ “sports”, “music” ]}Elasticsearch和关系型数据术语对照表:关系数据库 ⇒ 数据库 ⇒ 表 ⇒ 行 ⇒ 列(Columns)Elasticsearch ⇒ 索引 ⇒ 类型 ⇒ 文档 ⇒ 字段(Fields)Elasticsearch最关键的就是提供强大且丰富的索引功能，它的索引思路，就是将磁盘里的东西尽量搬进内存，减少磁盘随机读取次数(同时也利用磁盘顺序读特性)，结合各种奇妙的压缩算法，用及其苛刻的态度使用内存。当然了在提高搜索的性能的同时，难免会牺牲某些其他方面的性能，比如插入/更新，因为在插入数据的同时它还会为每个字段建立倒排索引。在传统的数据库中，由于二叉树的查找效率是logN，插入和删除的效率高，且在树的结构下插入新的节点不会移动全部节点，又结合于磁盘读取特性，传统的数据库使用B-Tree/B+-Tree。为了提高查询的效率，减少磁盘寻道次数，将多个值作为一个数组通过连续区间存放，一次寻道读取多个数据，同时也降低树的高度。建立倒排索引的流程：示例流程：得到的倒排索引如下:Posting ListElasticsearch分别为每个field都建立了一个倒排索引，Kate, John, 24, Female这些叫term（term的定义），而[1,2]就是Posting List。Posting list就是一个int的数组，存储了所有符合某个term的文档id。通过posting list这种索引方式似乎可以很快进行查找，比如要找age=24的同学，爱回答问题的小明马上就举手回答：我知道，id是1，2的同学。但是，如果这里有上千万的记录呢？如果是想通过name来查找呢？在传统的数据库中使用B-Tree减少磁盘寻道次数，直接将索引用一个b-tree树连接在一起并存入一个数据页中，而elasticsearch也使用同样的方法，它首先将term进行排序，并用字典树的方法将其连接起来形成term index。而建立这些term和文档id 的关系就需要前面两步，term index，和建立term dictionaryTerm index这棵树不会包含所有的term，它只包含的是term的一些前缀。主要是由于如果term太多，term index也会很大，放内存不现实。在mysql中是把索引存入硬盘，然后需要若干次读取磁盘进行数据寻找。而该字典树又像B-tree一样会存储该节点内的具体信息，类似，它的每个节点会存储该term index下的term dictionary blocks信息，而每个term dictionary block又会执行其对应的Posting List信息。再结合FST(Finite State Transducers)的压缩技术，可以使term index缓存到内存中。从term index查到对应的term dictionary的block位置之后，再去磁盘上找term，大大减少了磁盘随机读的次数。那FST压缩算法是什么。它用在什么地方呢？FSTs are finite-state machines that map a term (byte sequence) to an arbitrary output.FSTs是有限状态机，它将术语(字节序列)映射到任意输出。画个图你就知道。假设我们现在要将mop, moth, pop, star, stop and top(term index里的term前缀)映射到序号：0，1，2，3，4，5(term dictionary的block位置)。最简单的做法就是定义个Map，然后将对应数据存入map中，但是这样太消耗内存。而FST就是将单词分成单个字母通过⭕️和–>表示出来，0权重不显示。如果⭕️后面出现分支，就标记权重，最后整条路径上的权重加起来就是这个单词对应的序号。⭕️ 表示一种状态–>表示状态的变化过程，上面的字母/数字表示状态变化和权重FST就用于term index字典树和term index指向term dictionary blocks时 term dictionary blocks的存储。ES还对posting list 做了压缩，其压缩方法是：Frame Of Reference， Roaring bitmapsFrame Of Reference：原理就是通过增量，将原来的大数变成小数仅存储增量值，再精打细算按bit排好队，最后通过字节存储，而不是大大咧咧的尽管是2也是用int(4个字节)来存储。这个 Frame of Reference 的编码是有解压缩成本的。当进行查找的时候可以利用 skip list，除了跳过了遍历的成本，也跳过了解压缩这些压缩过的 block 的过程，从而节省了 cpu。Roaring bitmaps传统的Bitmap是一种数据结构，假设有某个posting list：[1,3,4,7,10]对应的bitmap就是：[1,0,1,1,0,0,1,0,0,1]虽然这个方法已经相对好，但还不算很压缩率高，且其缺点是存储空间随着 变量个数线性增长。而Roaring bitmaps，将posting list按照65535为界限分块，比如第一块所包含的文档id范围在065535之间，第二块的id范围是65536131071，以此类推。再用的组合表示每一组id，这样每组里的id范围都在0~65535内了，剩下的就好办了，既然每组id不会变得无限大，那么我们就可以通过最有效的方式对这里的id存储。可是为什么是以65535为界限?65535也是一个经典值，因为它=2^16-1，正好是用2个字节能表示的最大数（选用2个字节的原因是大部分情况，设置一个字节那最多表示256-1 个数，区间的长度太小，而 三个字节又比较难用short或者char表示，选用4个组件那区间的空间太大不合适），一个short的存储单位，注意到上图里的最后一行“If a block has more than 4096 values（如果这个块里面有超过4096个值时）, encode as a bit set, and otherwise as a simple array using 2 bytes per value”，如果是大块，用节省点用bitset存，小块就豪爽点，2个字节我也不计较了，用一个short[]存着方便。那为什么用4096来区分采用数组还是bitmap的阀值呢？这个是从内存大小考虑的，当block块里元素超过4096后，用bitmap更剩空间：采用bitmap需要的空间是恒定的: 65536/8 = 8192bytes而如果采用short[]，所需的空间是: 2*N(N为数组元素个数)更通俗的讲法是由于选用2个字节表示一个最大的数那么其占有的空间 65536/8 = 8192个字节，而如果是小块，且数值最大也是65535，用short类型来表示这个最大数值也只需要2个字节，那么8192个字节，就只能表示4096个数。如何减少文档数？Elasticsearch 有一个功能可以实现类似的优化效果，那就是 Nested Document。我们可以把一段时间的很多个数据点打包存储到一个父文档里，变成其嵌套的子文档。示例如下：{timestamp:12:05:01, idc:sz, value1:10,value2:11}{timestamp:12:05:02, idc:sz, value1:9,value2:9}{timestamp:12:05:02, idc:sz, value1:18,value:17}可以打包成：{max_timestamp:12:05:02, min_timestamp: 1205:01, idc:sz,records: [{timestamp:12:05:01, value1:10,value2:11}{timestamp:12:05:02, value1:9,value2:9}{timestamp:12:05:02, value1:18,value:17}]}这样可以把数据点公共的维度字段上移到父文档里，而不用在每个子文档里重复存储，从而减少索引的尺寸。这样** 使用了嵌套文档之后，对于 term 的 posting list 只需要保存父文档的 doc id 就可以了，可以比保存所有的数据点的 doc id 要少很多。如果我们可以在一个父文档里塞入 50 个嵌套文档，那么 posting list 可以变成之前的 1/50。**联合索引：上面说了半天都是单field索引，如果多个field索引的联合查询，倒排索引如何满足快速查询的要求呢？在posting list中利用跳表(Skip list)的数据结构快速做“与”运算，或者利用上面提到的bitset按位“与”先看看跳表的数据结构：将一个有序链表level0，挑出其中几个元素到level1及level2，每个level越往上，选出来的指针元素越少，查找时依次从高level往低查找，比如55，先找到level2的31，再找到level1的47，最后找到55，一共3次查找，查找效率和2叉树的效率相当，但也是用了一定的空间冗余来换取的。但是在posting list中如果进行联合索引时，由于已经建立好不同长度链表，将其转换为跳表结构体后，最短的posting list中的每个id，逐个在另外两个posting list中查找看是否存在，最后得到交集的结果。当posting list 中的blocking 长度大于4096时，其存储形式是 bitset，那么，直接按位与，得到的结果就是最后的交集。最后，总结：对于使用Elasticsearch进行索引时需要注意:不需要索引的字段，一定要明确定义出来，因为默认是自动建索引的同样的道理，对于String类型的字段，不需要analysis的也需要明确定义出来，因为默认也是会analysis的选择有规律的ID很重要，随机性太大的ID(比如java的UUID)不利于查询]]></content>
      <categories>
        <category>elasticsearch</category>
      </categories>
      <tags>
        <tag>elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[webrtc实现流程及原理探索]]></title>
    <url>%2F2019%2F09%2F20%2Fwebrtc%E5%AE%9E%E7%8E%B0%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%8E%9F%E7%90%86%E6%8E%A2%E7%B4%A2%2F</url>
    <content type="text"><![CDATA[目前实时流媒体主流有三种实现方式：WebRTC、HLS、RTMPHLS:是有苹果开发的 一种把流媒体拆分成多个独立小文件的技术，按照播放时间请求不同文件，把hls的文件进行解复用之后取出音视频数据然后丢给video去播放（Safari和安卓版的Chrome能直接播放hls）。它的优点是：使用了传统http协议，所以兼容性和稳定都非常好，服务端可以把hls文件上传到cdn，进而能够应对百万级别观众的直播，缺点是延时比较大，通常在10s以上，适合观众和主播没有什么交互的场景。因为一个hls文件时间长度通常在10s以上，再加上生成文件的时间就导致延迟很大。RTMP：是Adobe推出的，使用长连接，是一套完整的流媒体传输协议，使用flv视频容器，原生浏览器不支持（flash插件支持），不过可以使用websocket + MSE的方式，相关的类库比较少，在Android/IOS客户端上的直播应该用得比较多一点。相对于HLS请求分片的形式，RTMP由于使用长连接，接收不间断的数据流，它的延迟要比HLS小很多，通常是1~3秒，所以如果观众和主播之间有通话或者视频交互，这种方式的延迟是可以接受的。WebRTC：所有主流浏览器都支持，做到比RTMP提供更低的延迟和更小的缓冲率，官方还提供了配套的native的Andorid/IOS的库， 不过实际的实现可能是套一个webview，由webview启动webrtc，再把数据给native层渲染。（1）getUserMedia是负责获取用户本地的多媒体数据，如调起摄像头录像等。（2）RTCPeerConnection是负责建立P2P连接以及传输多媒体数据。（3）RTCDataChannel是提供的一个信令通道，在游戏里面信令是实现互动的重要元素。穿墙打洞要建立一个连接需要知道对方的IP地址和端口号，在局域网里面一台路由器可能会连接着很多台设备，例如家庭路由器接入宽带的时候宽带服务商会分配一个公网的IP地址，所有连到这个路由器的设备都共用这个公网IP地址。如果两台设备都用了同一个端口号创建套接字去连接服务，这个时候就会冲突，因为对外的IP是一样的。因此路由器需要重写IP地址/端口号进行区分，如下图所示：有两台设备分别用了相同的端口号建立连接，被路由器转换成不同的端口，对外网表现为相同IP地址不同端口号，当服务器给这两个端口号发送数据的时候，路由器再根据地址转换映射表把数据转发给相应的主机。所以当你在本地监听端口号为55020，但是对外的端口号并不是这个，对方用55020这个端口号是连不到你的。这个时候有两种解决方法，第一种是在路由器设置一下端口映射，如下图所示：上图的配置是把所有发往8123端口的数据包到转到192.168.123.20这台设备上。但是我们不能要求每个用户都这么配他们的路由器，因此就有了穿墙打洞，基本方法是先由服务器与其中一方（Peer）建立连接，这个时候路由器就会建立一个端口号内网和外网的映射关系并保存起来，如上面的外网1091就可以打到电脑的55020的应用上，这样就打了一个洞，这个时候服务器把1091端口加上IP地址告诉另一方（Peer），让它用这个打好洞的地址进行连接。这就是建立P2P连接穿墙打洞的原理，最早起源于网络游戏，因为打网络游戏经常要组网，WebRTC对NAT打洞进行了标准化。这个的有效性受制于用户的网络拓扑结构，因为如果路由器的映射关系既取决于内网的IP + 端口号，也取决于服务器的IP加端口号，这个时候就打不了洞了，因为服务器打的那个洞不能给另外一个外网的应用程序使用（会建立不同的映射关系）。相反如果地址映射表只取决于内网机器的IP和端口号那么是可行的。打不了洞的情况下WebRTC也提供了解决方法，即用一个服务器转发多媒体数据。这套打洞的机制叫ICE（Interactive Connectivity Establishment），帮忙打洞的服务器叫TURN服务，转发多媒体数据的服务器叫STUN服务。谷歌提供了一个turn server（https://webrtc.github.io/samples/src/content/peerconnection/trickle-ice/）除了默认提供的TURN服务打洞之外，还需要有一个websocket服务交换互连双方的信息。首先打开摄像头获取到本地的mediaStream，并把它添加到RTCPeerConnection的对象里面，然后创建一个本地的offer，这个offer主要是描述本机的一些网络和媒体信息，采用SDP（ Session Description Protocol）格式。然后把这个offer通过websocket服务发送给要连接的对方，对方收到后创建一个answer，格式、作用和offer一样，发送给呼叫方告知被呼叫方的一些信息。当任意一方收到对方的sdp信息后就会调setRemoteDescription记录起来。而当收到默认的ice server发来的打洞信息candidate之后，把candidate发送给对方（在setRemoteDesc之后），让对方发起连接，成功的话就会触发onaddstream事件，把事件里的event.stream画到video上面即可得到对方的影像。以上就是建立用webrtc建立p2p通信的过程。具体的代码执行流程如下其中需要注意的实现由：webrtc 开发之前必须了解的东西1、创建offer的时候带上参数：{ offerToReceiveAudio: true, offerToReceiveVideo: true }2、onicecandidate 必须写在 setLocalDescription 之前，因为一调用setLocalDescription，立马会产生icecandidate。3、pc.addTrack（或者addStream）必须在pc.createAnswer之前，如果你的offer没有带上参数（第一条），那么也应该在pc.createOffer()之前。因为offer或者answer带有媒体信息。4、webrtc 是 peer to peer ，不是peers to peers。A与B 相连，A需要new RTCPeerConnection，B也需要。A再与C相连，A还需要new RTCPeerConnection5、stun 服务器，是提供打洞的东西，turn服务器是提供数据中转的东西。打洞（Nat类型及穿透）请看我的另一篇博客，webrtc只支持 https和 localhost，所以局内网主机能开视频，另一端（另一台电脑）只能看。6、火狐报错：xxx failed（需要turn但根本没有turn服务器），还有一种，turn Server appears to be broken：这个是turn服务器限制连接数量，就是说人较多，你挤不上去了。免费的turn 是http://numb.viagenie.ca，去申请账号密码。免费的stun : stun:stun.freeswitch.org 、stun.ekiga.net自己部turn: github 搜 coturn个人网页：gusheng123.top，可测试多对多视频。其中废弃的api有navigator.getUserMeida(已废弃)，现在改为navigator.mediaDevices.getUserMedia;RTCPeerConnection.addStream被RTCPeerConnection.addTrack取代;STUN,TURN配置里的url现被urls取代；webrtc的api文档https://www.kaifaxueyuan.com/frontend/webrtc/webrtc-rtcpeerconnection-apis.htmlsdp消息分享后，在进行连接之前，会进行候选者检索。本机候选者进行webrtc的端口转换的协议叫做STUN协议，用于收集，srflx (可用于p2p)的候选者TURN服务器，又叫中继服务器，用于收集中继类型的 webrtc候选者。李超教程p2p直播间流程图当调用createOffer和createAnswer时就会自己触发 onicecandidate 事件]]></content>
      <categories>
        <category>webrtc</category>
      </categories>
      <tags>
        <tag>webrtc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RTP,RTMP,RTCP,RTSP的区别]]></title>
    <url>%2F2019%2F09%2F20%2FRTP-RTMP-RTCP-RTSP%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[RTP(Real-time Transport Protocol)实时传输协议RTP是用于Internet上针对多媒体数据流的一种传输协议。位于应用层。RTP由两个部分组成:RTP—-传送具有实时属性的数据；RTCP控制协议（RTCP）—-监控服务质量并传送正在进行的会话参与者的相关信息。RTP协议是建立在UDP协议上的。RTP协议详细说明了在互联网上传递音频和视频的标准数据包格式。RTP协议的目的是提供实时数据（如交互式的音频和视频）的端到端传输服务，因此在RTP中没有连接的概念，它可以建立在底层的面向连接或面向非连接的传输协议之上；RTP也不依赖于特别的网络地址格式，底层传输协议只需要支持组帧（Framing）和分段（Segmentation）就足够了；另外RTP本身还不提供任何可靠性机制，这些都要由传输协议或者应用程序自己来保证。在典型的应用场合下，RTP一般是在传输协议之上作为应用程序的一部分加以实现的。RTP并不保证传送或防止无序传送，也不确定底层网络的可靠性。RTP实行有序传送，RTP中的序列号允许接收方重组发送方的包序列，同时序列号也能用于决定适当的包位置，例如：在视频解码中，就不需要顺序解码。RTCP(Real-time Transport Control Protocol)实时传输控制协议介绍：RTCP控制协议需要与RTP数据协议一起配合使用，当应用程序启动一个RTP会话时将同时占用两个端口，分别供RTP和RTCP使用。RTP本身并不能为按序传输数据包提供可靠的保证，也不提供流量控制和拥塞控制，这些都由RTCP来负责完成。RTCP为RTP媒体流提供信道外控制。功能：通常RTCP会采用与RTP相同的分发机制，向会话中的所有成员周期性地发送控制信息，应用程序通过接收这些数据，从中获取会话参与者的相关资料，例如：传输字节数，传输分组数，丢失分组数，时延抖动，单向和双向网络延迟等等。，从而能够对服务质量进行控制或者对网络状况进行诊断。RTCP收集相关媒体连接的统计信息，网络应用程序可以利用RTCP所提供的信息试图提高服务质量，比如限制信息流量或改用压缩比较小的编解码器。RTCP本身不提供数据加密或身份认证，其伴生协议SRTCP（安全实时传输控制协议）则可用于此类用途。RTSP（Real Time Streaming Protocol）实时流协议RTSP是由Real Network和Netscape共同提出的如何有效地在IP网络上传输流媒体数据的应用层协议。RTSP对流媒体提供了诸如暂停，快进等控制，但它本身并不传输数据，RTSP的作用相当于流媒体服务器的远程控制。服务器端可以自行选择使用TCP或UDP或组播UDP或RTP等通道来发送数据，具有很好的扩展性。|它的语法和运作跟HTTP 1.1类似，RTSP协也议定义了一对多应用程序如何有效通过IP网络传送多媒体数据。RTSP在体系结构上位于RTP和RTCP之上。HTTP与RTSP相比，HTTP传送HTML，而RTP传送的是多媒体数据。HTTP请求由客户机发出，服务器做出响应；RTSP可以是双向的，即客户机和服务器都可以发出请求。不特别强调时间同步，所以比较能容忍网络延迟。RTSP之所以特意使用与HTTP/1.1类似的语法和操作，在很大程度上是为了兼容现有的Web基础结构，正因如此，HTTP/1.1的扩展机制大都可以直接引入到RTSP中。由RTSP控制的媒体流集合可以用表示描述（Presentation Description）来定义，所谓表示是指流媒体服务器提供给客户机的一个或者多个媒体流的集合，而表示描述则包含了一个表示中各个媒体流的相关信息，如数据编码/解码算法、网络地址、媒体流的内容等。虽然RTSP服务器同样也使用标识符来区别每一流连接会话（Session），但RTSP连接并没有被绑定到传输层连接（如TCP等），也就是说在整个 RTSP连接期间，RTSP用户可打开或者关闭多个对RTSP服务器的可靠传输连接以发出RTSP 请求。此外，RTSP连接也可以基于面向无连接的传输协议（如UDP等）。（2）RTSP协议是共有协议，并有专门机构做维护。.（3）RTSP协议一般传输的是 ts、mp4 格式的流。（4）RTSP传输一般需要 2-3 个通道，命令和数据通道分离。RTMP(Real Time Messaging Protocol)实时消息传输协议RTMP（Real Time Messaging Protocol）是Adobe Systems公司为Flash播放器和服务器之间音频、视频和数据传输开发的开放协议。它有三种变种：（1）工作在TCP之上的明文协议，使用端口1935；（2）RTMPT封装在HTTP请求之中，可穿越防火墙；（3）RTMPS类似RTMPT，但使用的是HTTPS连接。（4）RTMP协议一般传输的是 flv，f4v 格式流。（5）RTMP一般在 TCP 1个通道上传输命令和数据RTMP视频播放的特点：（1）RTMP协议是采用实时的流式传输，所以不会缓存文件到客户端，这种特性说明用户想下载RTMP协议下的视频是比较难的；（2）视频流可以随便拖动，既可以从任意时间点向服务器发送请求进行播放，并不需要视频有关键帧。相比而言，HTTP协议下视频需要有关键帧才可以随意拖动。（3）RTMP协议支持点播/回放（通俗点将就是支持把flv,f4v,mp4文件放在RTMP服务器，客户端可以直接播放），直播（边录制视频边播放）。HLS (HTTP Live Streaming)HTTP Live Streaming(HLS)是苹果公司实现的基于HTTP的流媒体传输协议，可实现流媒体的直播和点播，主要应用于iOS系统。HLS点播是分段HTTP点播，不同在于它的分段非常小。要实现HLS点播，重点在于对媒体文件分段，目前有不少开源工具可以使用。相对于常见的流媒体直播协议，HLS直播最大的不同在于，直播客户端获取到的并不是一个完整的数据流，HLS协议在服务器端将直播数据流存储为连续的、很短时长的媒体文件（MPEG-TS格式），而客户端则不断的下载并播放这些小文件，因为服务器总是会将最新的直播数据生成新的小文件，这样客户端只要不停的按顺序播放从服务器获取到的文件，就实现了直播。由此可见，基本上可以认为，HLS是以点播的技术方式实现直播。特点：由于数据通过HTTP协议传输，所以完全不用考虑防火墙或者代理的问题，而且分段文件的时长很短，客户端可以很快的选择和切换码率，以适应不同带宽条件下的播放。不过HLS的这种技术特点，决定了它的延迟一般总是会高于普通的流媒体直播协议。]]></content>
      <categories>
        <category>基础</category>
      </categories>
      <tags>
        <tag>音视频</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[集群下如何共享session]]></title>
    <url>%2F2019%2F09%2F20%2F%E9%9B%86%E7%BE%A4%E4%B8%8B%E5%A6%82%E4%BD%95%E5%85%B1%E4%BA%ABsession%2F</url>
    <content type="text"><![CDATA[Session是在服务端保存的一个数据结构，用来跟踪用户的状态，这个数据可以保存在集群、数据库、文件中；session的用途：session的实现方法Cookie是客户端保存用户信息的一种机制，用来记录用户的一些信息，也是实现Session的一种方式，Cookie是浏览器保存信息的一种方式，可以理解为一个文件，保存到客户端了啊，服务器可以通过响应浏览器的set-cookie的标头，得到Cookie的信息。你可以给这个文件设置一个期限，这个期限呢，不会因为浏览器的关闭而消失啊。其实大家应该对这个效果不陌生，很多购物网站都是这个做的，即使你没有买东西，他也记住了你的喜好，现在回来，会优先给你提交你喜欢的东西；用express 来实现cookies知识的学习https://blog.csdn.net/henni_719/article/details/53612499cookies和session的区别相关知识：cookie的存活期：默认为-1会话Cookie：当存活期为负数，把Cookie保存到浏览器上持久Cookie：当存活期为正数，把Cookie保存到文件中有人问，如果客户端的浏览器禁用了 Cookie 怎么办？一般这种情况下，会使用一种叫做URL重写的技术来进行会话跟踪，即每次HTTP交互，URL后面都会被附加上一个诸如 sid=xxxxx 这样的参数，服务端据此来识别用户。该方法的实现机制为：● 先判断当前的 Web 组件是否启用 Session，如果没有启用 Session，直接返回参数 url。● 再判断客户端浏览器是否支持 Cookie，如果支持 Cookie，直接返回参数 url；如果不支持 Cookie，就在参数 url 中加入 Session ID 信息，然后返回修改后的 url。大部分手机浏览器不支持cookies集群下共享session 的方法：客户端cookie加密当用户登陆成功以后，把网站域名、用户名、密码、token、 session有效时间全部采用cookie的形式写入到客户端的cookie里面。如果用户从一台Web服务器跨越到另一台服务器的时候，我们的程序主动去检测客户端的cookie信息，进行判断，然后提供对应的服务，当然，如果cookie过期，或者无效，自然就不让用户继续服务了。优点：简单、高效，也不会加大数据库的负担。缺点：cookie安全性较低，虽然它已经加了密，但是还是可以伪造的。但是如果客户端把cookie禁掉了的话，那么session就无从同步了，这样会给网站带来损失；cookies中数据不能太多，最好只有个用户id。或者这个方法： 使用Nginx的ip_hash策略来做负载均衡ip_hash策略的原理：根据Ip做hash计算，同一个Ip的请求始终会定位到一台web服务器上。用户—> 浏览器 —-> Nginx（ip_hash） —–> n（多）台Web服务器同一个用户（Ip）—> 浏览器 —-> Nginx（ip_hash） —–> A Web服务器此时假如用户IP为 192.168.1.110 被hash到 A web服务器，那么用户的请求就一直会访问A web服务器了。优点：配置简单，只需要在Nginx中配置好ip_hash 策略对应用无侵入性，应用不需要改任何ip_hash策略会很均匀的讲用户请求的ip分配到web服务器上，并且可以动态的水平扩展web服务器（只需在配置中加上服务器即可）缺点:假如有一台Tomcat 宕机或者重启，那么这一台服务器上的用户的Session信息丢失，导致单点故障。session replication，如tomcat自带session共享，主要是指集群环境下，多台应用服务器之间同步session，使session保持一致，对外透明。 如果其中一台服务器发生故障，根据负载均衡的原理，调度器会遍历寻找可用节点，分发请求，由于session已同步，故能保证用户的session信息不会丢失，会话复制,。优点：通过应用服务器配置即可，无需改动代码。缺点：性能随着服务器增加急剧下降，而且容易引起广播风暴；session数据需要序列化，影响性能。Session同步会有延迟，会影带宽受限于内存资源，在大用户量，高并发，高流量场景，会占用大量内存，不适合！session复制的原理http://book.51cto.com/art/201202/319431.htmsession复制的拓扑结构：点对点：点对点复制的拓扑结构的优势：是不需要额外的进程和产品来避免单点失败，从而减少了配置和维持额外进程或产品的时间和费用的成本。劣势：但这个拓扑结构的局限性就是它需要占用一定的内存空间，因为每个服务端都需要备份这个复制域里所有 session 的信息。假如一个 session 需要 10KB 的空间来存储信息，那么当 100 万个用户同时登陆到这个系统中时，每个应用服务器就需要花费 10GB 的内存空间来保存所有 session 的信息。它的另一个局限性是每一个 session 信息的修改都会被复制到其他所有的应用服务器上，这极大地影响了整个系统的性能。3.使用数据库保存session这种共享session的方式即将session信息存入数据库中，其它应用可以从数据库中查出session信息。优点：使用数据库来保存session,就算服务器宕机了也没事，session照样在。缺点：每次请求都需要对数据库进行读写，session的并发读写在数据库中完成，会加大数据库的IO，对数据库性能要求比较高。我们需要额外地实现session淘汰逻辑代码，即定时从数据库表中更新和删除session信息，增加了工作量。数据库读写速度较慢，不利于session的适时同步。使用redis或memcache来保存session提供一个集群保存session共享信息，其他应用统统把自己的session信息存放到session集群服务器组。当应用系统需要session信息的时候直接到session群集服务器上读取。目前大多都是使用Memcache或redis来对Session进行存储。以这种方式来同步session，不会加大数据库的负担，并且安全性比用cookie大大的提高，把session放到内存里面，比从文件中读取要快很多。]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[谈关系型数据库的外键]]></title>
    <url>%2F2019%2F09%2F20%2F%E8%B0%88%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E5%A4%96%E9%94%AE%2F</url>
    <content type="text"><![CDATA[外键多了会有很多维护问题吧？首先，外键本身是为了实现强一致性，所以如果需要正确性>性能的话，还是建议使用外键，它可以让我们在数据库的层面保证数据的完整性和一致性。当然不用外键，你也可以在业务层进行实现。不过，这样做也同样存在一定的风险，因为这样，就会让业务逻辑会与数据具备一定的耦合性。也就是业务逻辑和数据必须同时修改。而且在工作中，业务层可能会经常发生变化。当然，很多互联网的公司，尤其是超大型的数据应用场景，大量的插入，更新和删除在外键的约束下会降低性能，同时数据库在水平拆分和分库的情况下，数据库端也做不到执行外键约束。另外，在高并发的情况下，外键的存在也会造成额外的开销。因为每次更新数据，都需要检查另外一张表的数据，也容易造成死锁。所以在这种情况下，尤其是大型项目中后期，可以采用业务层来实现，取消外键提高效率。不过在SQL学习之初，包括在系统最初设计的时候，还是建议你采用规范的数据库设计，也就是采用外键来对数据表进行约束。因为这样可以建立一个强一致性，可靠性高的数据库结构，也不需要在业务层来实现过多的检查。当然在项目后期，业务量增大的情况下，你需要更多考虑到数据库性能问题，可以取消外键的约束，转移到业务层来实现。而且在大型互联网项目中，考虑到分库分表的情况，也会降低外键的使用。不过在SQL学习，以及项目早期，还是建议你使用外键。在项目后期，你可以分析有哪些外键造成了过多的性能消耗。一般遵循2/8原则，会有20%的外键造成80%的资源效率，你可以只把这20%的外键进行开放，采用业务层逻辑来进行实现，当然你需要保证业务层的实现没有错误。不同阶段，考虑的问题不同。当用户和业务量增大的时候，对于大型互联网应用，也会通过减少外键的使用，来减低死锁发生的概率，提高并发处理能力。]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[音视频编解码基础知识]]></title>
    <url>%2F2019%2F09%2F20%2F%E9%9F%B3%E8%A7%86%E9%A2%91%E7%BC%96%E8%A7%A3%E7%A0%81%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%2F</url>
    <content type="text"><![CDATA[音视频编解码器有：OPUS 最新的协议，支持 口 耳模式 不支持RTMPAAC 用于直播系统多 支持RTMP 有高保真的效果Speex 支持回音消除，降噪算法 支持RTMPG.711 常用于固话音频编解码频带和压缩性能对比图AAC诞生的目的是为了取代MP3mp3的规范是mpeg2 （mpeg2 有损压缩）mpeg4 规范中，AAC加入了SBR技术和PS技术 相较MPEG2音质更好，压缩比更高AAC的常见规格 是AAC LC, AAC HE V1, AAC HE V2AAC HE V2 = AAC HE V1 + PSAAC HE V1 = AAC + SBRLC = low complexityhe = lc + sbr (spectral band replication 分频复用)在lc中采样率固定的时候 低频采用的 次数 会很多，而高频采用次数会很少，不协调，he则降低低频采样次数增加高频采样次数he v2 = aac lc + sbr +ps (双声道分别保存) 一个声道的数据完整保存，另一个声道只存差异数据文件格式adif 格式 这种格式只能从头开始解码，音频各种信息都保存到文件头部adts格式 每一帧都有一个同步字，使得在流传输的时候可以从任何位置开始解码在RTMP和FLV文件格式里都是使用adtsAAC的编解码库 效率对比libfdk_aac > ffmpeg_aac > libfaac > libvo_aacenc手机是通过音视频采集模块将数据采集成 PCM/YUV数据，然后通过硬件编码器将它们压缩成 AAC（LC）/H264。H264编码格式中B桢是向前向后参考帧，B帧越多，压缩比越高 ，但是在直播系统中，得等到下一帧来了才能解码，所以延迟会高GOF = group of frame 一组帧 组帧头是SPS, PPS(他们两个被划入I帧)SPS 序列参数集， 存放帧信息，PPS 图像参数集花屏的原因： GOF中的P帧丢失， 避免花屏，但一个GOF钟的P帧丢失就不显示这个GOF,但是会引起卡顿视频编解码器x264 市面上用最多x265 压缩比更高，占用cpu更多open H264 性能低一些相对于x264支持SVC（视频分层传输，根据网络情况，选择发送层数）技术SVC在移动端，很多硬件解码不支持，只能使用软编，使用svc可以适用各种带宽情况H264压缩技术基础概念帧内预测压缩，对人眼不敏感的数据进行压缩帧间预测压缩 压缩帧与帧之间相同数据DCTcbac压缩，无损压缩，类似于哈夫曼编码将每一帧数据进行宏块划分，宏块内部再进行子块划分，对相似性高的 帧进行帧规划，形成帧分组帧间预测压缩 过程组内宏块查找 -》 运动估算 -》 运动矢量和补偿压缩 -》得到运动矢量数据 + 基础背景数据帧内预测压缩过程对帧内的所有宏块进行选择，选择一种帧内预测模式（共九种模式）对已经进行预测的图片和原图进行对比 计算出帧内预测残缺值，得到残缺值图，如下右图 黑色部分最后把预测的图片和残缺值进行保存压缩。解压的时候 把 预测图片和 残缺值进行相加即可得出原图DCT压缩把宏块进行量化，然后丢入DCT压缩算法，得到量化结果VLC压缩 是MPEG2 规范中的 （类似哈夫曼编码的） 但是是有损的H264规范中 使用的是CABAC 压缩，还增加了 上下文适用的压缩规则 无损压缩H264的结构图H264编码分层NAL 层以太网最多1500字节 为传输单元 而H264的帧大于1500字节。所以需要进行拆包，NAL层就进行拆包组包工作VCL video coding layer 视频数据编码层 就是如上讲是视频压缩算法编码算法等码流的概念：SODB string of data bits 原始码流，长度不一定是8的倍速 由VCL产生RBSP 在SODB 后补位 补足为8的倍速EBSP 在每个帧的起始位 加入特殊标识NALU 就是在EBSP上 加一个字节的NAL起始头形成NAL单元H264中把一个帧分为 n个切片， 一帧至少有一个切片（因为在网络传输的时候，可能会把一帧拆开进行传输，就按照切片分）nal单元 = nalu 头 + 一个切片 （切片头 + 切片数据）切片和宏块的关系起始码是起始标记 0x00 0x01YUV 颜色编码方法 Y 明亮度 UV 表示色度YUV的组织形式yuv 存储格式]]></content>
      <categories>
        <category>音视频</category>
      </categories>
      <tags>
        <tag>音视频</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式事务解决方案]]></title>
    <url>%2F2019%2F09%2F20%2F%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[当我们的单个数据库的性能产生瓶颈的时候，我们可能会对数据库进行分区，这里所说的分区指的是物理分区，分区之后可能不同的库就处于不同的服务器上了，这个时候单个数据库的ACID已经不能适应这种情况。于是使用新的理论来保证分布式事务的一致性。CAP定理一致性(Consistency) ：保证服务中所有的节点保存的数据都是一致的。可用性(Availability) ： 读写操作在单台服务器出问题后，在其他服务器上依然能够完成读写操作重点在于：某个读写操作在出问题的机器上不能读写了，但是在其他机器可以完成分区容错性(Partition tolerance) ： 即使出现单个组件无法可用,操作依然可以完成。（分布式系统遇到网络分区故障的时候，某个分区故障了，但是其他的分区还可用保证一致性和可用性。这样丧失了分区容错性。且剩下的服务不会因为坏掉的部分节点而丧失一致性和可用性）重点在于：部分服务器因网络问题，业务依然能够继续运行三种特性只能同时满足两个。可以使用zookeeper和euraka架构的例子。zookeeper使用leader选举（这个制度，会导致这个服务组件无法对外提供服务丧失了可用性）制度保证了一致性和分区容错性，服务实例自动切换euraka节点（由于原euraka节点挂掉了，但euraka上面的数据还没同步到其他节点上，此时即使服务实例切换了节点，但是在一致性上就没有得到保障，虽然服务实例通过心跳包机制或者ack机制，发现实例挂掉了，再重新注册，保障了最终一致性。）重新注册保证了可用性和分区容错性。在分布式系统中，我们往往追求的是可用性，它的重要程序比一致性要高，那么如何实现高可用性呢？ 前人已经给我们提出来了另外一个理论，就是BASE理论Basically Available（基本可用）Soft state（软状态）Eventually consistent（最终一致性）BASE理论是对CAP中的一致性和可用性进行一个权衡的结果，理论的核心思想就是：我们无法做到强一致，但每个应用都可以根据自身的业务特点，采用适当的方式来使系统达到最终一致性常见的处理方式有：基于XA协议的两阶段提交方案，TCC方案，基于消息的最终一致性方案基于XA协议的两阶段提交方案：事务调度器和分布在各地的资源管理器通过两阶段提交方式来完成一个全局事务。第一阶段是表决阶段，所有参与者都将本事务能否成功的信息反馈发给协调者；第二阶段是执行阶段，协调者根据所有参与者的反馈，通知所有参与者，步调一致地在所有分支上提交或者回滚。虽然两阶段提交方案应用非常广泛，几乎所有商业OLTP数据库都支持XA协议。存在的问题有：2.1 同步阻塞 所有事务参与者在等待其它参与者响应的时候都处于同步阻塞状态，无法进行其它操作。2.2 单点问题 协调者在 2PC 中起到非常大的作用，发生故障将会造成很大影响。特别是在阶段二发生故障，所有参与者会一直等待状态，无法完成其它操作。2.3 数据不一致 在阶段二，如果协调者只发送了部分 Commit 消息，此时网络发生异常，那么只有部分参与者接收到 Commit 消息，也就是说只有部分参与者提交了事务，使得系统数据不一致。2.4 太过保守 任意一个节点失败就会导致整个事务失败，没有完善的容错机制。TCC方案：TCC方案在电商、金融领域落地较多。这种方案不借助MQ。它类似于关系型数据库事务的三种操作：DML、Commit和Rollback，其将整个业务逻辑的每个分支显式的分成了Try、Confirm、Cancel三个操作。Try部分完成业务的准备工作，confirm部分完成业务的提交，cancel部分完成事务的回滚。事务开始时，业务应用会向事务协调器注册启动事务。之后业务应用会调用所有服务的try接口，完成一阶段准备。之后业务应用收到try接口的返回情况，然后决定给事务调度器调用confirm接口或者cancel接口。如果接口调用失败，会进行重试。TCC方案让应用自己定义数据库操作的粒度（粒度小主要体现在，相较于2pc方式，try阶段相较于2pc的预备阶段，它提前锁定资源的，然后再执行后续操作，如果confirm执行超时或者失败即可回退，而2pc的预备阶段是先把需要的资源锁住，如果资源不够就返回失败，在执行提交事务的过程中如果某一个操作执行失败，那么由于没有回退操作，那么其他资源就会一直被锁定）。由于Confirm和Cancel操作可能被重复调用，故要求Confirm和Cancel两个接口必须是幂等的。缺点：● 对应用的侵入性强。业务逻辑的每个分支都需要实现try、confirm、cancel三个操作，应用侵入性较强，改造成本高。● 实现难度较大。需要按照网络状态、系统故障等不同的失败原因实现不同的回滚策略。为了满足一致性的要求，confirm和cancel接口必须实现幂等。基于本地消息表的最终一致性方案：核心思想是将分布式事务拆分成本地事务进行处理。消息生产方，需要额外建一个消息表，并记录消息发送状态。消息表和业务数据要在一个事务里提交，也就是说他们要在一个数据库里面。然后消息会经过MQ发送到消息的消费方。如果消息发送到消息队列或者消息消费放失败，会进行重试发送。消息消费方，需要处理这个消息，并完成自己的业务逻辑。此时如果本地事务处理成功，表明已经处理成功了，就会发一个消息返回给消息生产方，修改消息表中的状态。如果处理失败，那么就会重试执行。如果是业务上面的失败，可以给生产方发送一个业务补偿消息，通知生产方进行回滚等操作。这种方案遵循BASE理论，采用的是最终一致性，笔者认为是这几种方案里面比较适合实际业务场景的，即不会出现像2PC那样复杂的实现(当调用链很长的时候，2PC的可用性是非常低的)，也不会像TCC那样可能出现确认或者回滚不了的情况。优点： 一种非常经典的实现，避免了分布式事务，实现了最终一致性。缺点： 消息表会耦合到业务系统中，如果没有封装好的解决方案，会有很多杂活需要处理。基于消息队列的事务方式方案：有一些第三方的MQ是支持事务消息的，比如RocketMQ，他们支持事务消息的方式也是类似于采用的二阶段提交，但是市面上一些主流的MQ都是不支持事务消息的，比如 RabbitMQ 和 Kafka 都不支持。操作流程如下：1.发送prepare消息，该消息对Consumer不可见2.执行本地事务3.若本地事务执行成功，则向MQ提交消息确认发送指令；若本地事务执行失败，则向MQ发送取消指令4.若MQ长时间未收到确认发送或取消发送的指令，则向业务系统询问本地事务状态，并做补偿处理。优点： 实现了最终一致性，不需要依赖本地数据库事务。也不依赖分布式事务。缺点： 实现难度大，主流MQ不支持。]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式，集群，微服务的理解]]></title>
    <url>%2F2019%2F09%2F20%2F%E5%88%86%E5%B8%83%E5%BC%8F%EF%BC%8C%E9%9B%86%E7%BE%A4%EF%BC%8C%E5%BE%AE%E6%9C%8D%E5%8A%A1%E7%9A%84%E7%90%86%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[分布式：一个业务分拆多个子业务，部署在不同的服务器上集群：同一个业务，部署在多个服务器上微服务：是一种架构风格，一个大型复杂软件应用由一个或多个微服务组成。系统中的各个微服务可被独立部署，微服务之间是松耦合的。每个微服务仅关注于完成一件任务并很好地完成该任务。在所有情况下，每个任务代表着一个小的业务能力。分布式是以缩短单个任务的执行时间来提升效率的，而集群则是通过提高单位时间内执行的任务数来提升效率。采用集群方案，同样提供 10 台服务器，每台服务器都能独立处理这个任务。假设有 10 个任务同时到达，10 个服务器将同时工作，1 小时后，10 个任务同时完成，这样，整身来看，还是 1 小时内完成一个任务！采用微服务方案，为了不因为某个模块的升级和BUG影响现有的系统业务。微服务与分布式的细微差别是，微服务的应用不一定是分散在多个服务器上，他也可以是同一个服务器。需注意的地方：分布式模式下需要做好事务管理和单点故障的问题。集群模式是不同服务器部署同一套服务对外访问，实现服务的负载均衡。注：集群模式需要做好session共享，确保在不同服务器切换的过程中不会因为没有获取到session而中止退出服务。一般配置Nginx*的负载容器实现：静态资源缓存、Session共享可以附带实现，Nginx支持五万个并发量。微服务模式下：1）单体应用拆分为分布式系统后，进程间的通讯机制和故障处理措施变的更加复杂。2）系统微服务化后，一个看似简单的功能，内部可能需要调用多个服务并操作多个数据库实现，服务调用的分布式事务问题变的非常突出。3）微服务数量众多，其测试、部署、监控等都变的更加困难。但是实际中dubbo可以支持多种通讯协议，springcloud可以非常好的支持restful调用。对于第三个问题，随着docker、devops技术的发展以及各公有云paas平台自动化运维工具的推出，微服务的测试、部署与运维会变得越来越容易。]]></content>
      <tags>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[test_pic]]></title>
    <url>%2F2019%2F09%2F20%2Ftest-pic%2F</url>
    <content type="text"><![CDATA[]]></content>
  </entry>
  <entry>
    <title><![CDATA[test to use blog]]></title>
    <url>%2F2019%2F09%2F19%2Ftest-to-use-blog%2F</url>
    <content type="text"><![CDATA[]]></content>
  </entry>
</search>
